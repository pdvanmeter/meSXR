"""
"""
import os
import sys
import time
import numpy as np
import cPickle as pickle

import mesxr.analysis.data as data
import mesxr.model.detector as det
import mesxr.model.plasma as plasma
import mesxr.model.physical_profiles as phys
import mesxr.analysis.data as data

# Default save location for k_hat scans
grid_dir = '/home/pdvanmeter/analysis/python/mesxr_temp_analysis/k_hat_scans'

# ---------------------------------------------------- Grid Scan Classes ----------------------------------------------------

# Fixed parameters
shot = 1190412078
frame = 10
Ew = 300.
num_cores = 24

delta_a = 0.06
delta_h = 0.01
ne = 0.7

# Charge-sharing parameters
params = np.array([-0.00094515,  0.02248114, -0.18196199,  0.58567633])
k_fit = np.poly1d(params)

slope = np.concatenate([np.ones(20)*k_fit(2), k_fit(np.linspace(2, 12, num=100)), np.zeros(100)])/1000.
cs_en = np.concatenate([np.linspace(0, 2, num=20), np.linspace(2, 12, num=100), np.linspace(12, 30, num=100)])*1000.

# Generate the fixed profiles
MST_data = data.load_ME(shot, frames=[frame], center_only=True, remove_edges=True)
thresholds = MST_data['thresholds']
Ec_map = thresholds[:,100]*1000.
Ew_map = np.ones(487)*Ew

ne_profile = phys.Electron_Density_Alpha(ne, alpha=4.2, beta=4.0, delta_a=delta_a, delta_h=delta_h)
nH_profile = phys.Neutral_Density_Profile(17.5)
ni_Al_profile = phys.Ion_Density_Alpha(3.0E-3, alpha=15, beta=2, element='Al', delta_a=delta_a, delta_h=delta_h)

class grid_point(object):
	def __init__(self, Te0, alpha, nAl0):
		# Put together the temperature profile
		self.Te0 = Te0
		self.alpha = alpha
		self.nAl0 = nAl0

		self.Te = phys.Temperature_Alpha(self.Te0, alpha=self.alpha, beta=4.0, delta_a=delta_a, delta_h=delta_h)
		self.nAl = phys.Ion_Density_Alpha(self.nAl0, alpha=15, beta=2, element='Al', delta_a=delta_a, delta_h=delta_h)

	def take_data(self):
		# Build the plasma object
		MST_plasma = plasma.Plasma(Te_profile=self.Te, ne_profile=ne_profile, nH_profile=nH_profile)
		MST_plasma.add_ions('Al', self.nAl, ignore_stages=range(1,7), lines=False)

		# Build the detector object
		p3det = det.Pilatus3_Detector(Ec_map, Ew_map, num_cores=num_cores, cs_slope=slope, cs_en=cs_en)
		p3det.look_at_plasma(MST_plasma)

		counts = p3det.take_data(1.0)
		tiempo = np.array([1])
		MST_sim = data.load_ME_sim([4.0*counts], tiempo, thresholds, remove_edges=True)
		kh_sim = data.get_k_hat(MST_sim, frame=0, start_n=0, end_n=59)
		self.k_hat = kh_sim['k_hat']
		self.sigma = kh_sim['sigma']
		self.x_avg = kh_sim['x_avg']

class plasma_grid(object):
	def __init__(self, params_Te0, params_alpha, params_nAl):
		self.params_Te0 = params_Te0
		self.params_alpha = params_alpha
		self.params_nAl = params_nAl
		self.grid = np.empty([len(self.params_Te0), len(self.params_alpha), len(self.params_nAl)], dtype=object)

		for i, Te0 in enumerate(self.params_Te0):
			for j, alpha in enumerate(self.params_alpha):
				for k, nAl0 in enumerate(self.params_nAl):
					self.grid[i,j,k] = grid_point(Te0, alpha, nAl0)

	def evaluate_grid(self, quiet=False, save=True, fname='k_hat_grid_400kA_PPCD.pkl', wait_time=2.0):
		for i, Te0 in enumerate(self.params_Te0):
			if not quiet:
				print('Starting scan for Te0 = {0:.2f} eV, {1:.1f}% complete.'.format(Te0, 100.0*i/len(self.params_Te0)))
				sys.stdout.write('Scanning alpha: ')
				sys.stdout.flush()

			for j, alpha in enumerate(self.params_alpha):
				sys.stdout.write('\nStarting alpha = {0:.1f}:'.format(alpha))
				for k, nAl0 in enumerate(self.params_nAl):
					self.grid[i,j,k].take_data()
					time.sleep(wait_time)

					if not quiet:
						sys.stdout.write('|')
						sys.stdout.flush()
					

                if save:
                    pickle.dump(self.grid, open(os.path.join(grid_dir, fname), 'wb'))

# ----------------------------------------------------- Analysis -----------------------------------------------------

def k_hat_bayesian_PPCD_midE(data_dict, frame=0, delta_a = 0.06, delta_h = 0.01, num_samples = 1000, smoothing=False, smooth_type='gauss',
                             grid_file='k_grid_Mylar.pkl', start_n = 13, end_n = 46):
    """
    Input is a dictionary generated by the mesxr.analysis.data load_ME family of functions. The relative frame index can
    be adjusted as desired.
    """
    # Load in the model grid
    k_grid = pickle.load(open(os.path.join(grid_dir, grid_file), 'rb'))
    Te0 = k_grid.params_Te0
    alpha = k_grid.params_alpha

    # This is a workaround until I make a new (Te0, alpha) matrix
    indices = range(start_n, end_n+1)

    # Process the input data as requested
    if smoothing == False:
        kh_data = data.get_k_hat(data_dict, frame=frame, start_n=start_n, end_n=end_n)

    else:
        print('Feature not yet available')
    
    k_data = kh_data['k_hat']
    k_data_err = kh_data['sigma']

    # Compute the likelihood function
    log_likelihood = np.zeros([len(Te0), len(alpha)])

    for temp_n in range(len(Te0)):
        for alpha_n in range(len(alpha)):
            log_likelihood[temp_n, alpha_n] = np.sum(-1.0*(k_data - k_grid.grid[temp_n, alpha_n].k_hat[indices])**2 / (2*k_data_err**2))
            
    p_of_k = np.exp(log_likelihood)

    # Compute marginal distributions and the evidence to normalize the distribution
    proj_Te = np.trapz(p_of_k, x=alpha, axis=1)
    proj_alpha = np.trapz(p_of_k, x=Te0, axis=0)
    norm = np.trapz(proj_Te, x=Te0)

    marginal_Teo = proj_Te / norm
    marginal_alpha = proj_alpha / norm

    # Some basic stats
    Te0_mean = np.trapz(marginal_Teo*Te0, x=Te0)
    Te0_mode = Te0[marginal_Teo.argmax()]
    alpha_mean = np.trapz(marginal_alpha*alpha, x=alpha)
    alpha_mode = alpha[marginal_alpha.argmax()]

    # Sample the distribution
    rand_Te0, rand_alpha = sample_2d(num_samples, p_of_k, Te0, alpha)
    Te_samples = [phys.Temperature_Alpha(temp, alpha=al, beta=4.0, delta_a=delta_a, delta_h=delta_h) for temp, al in zip(rand_Te0, rand_alpha)]

    # Evaluate the random profiles at 100 spatial points and build up statistics
    y_vals = np.linspace(0, 0.52, num=100)
    temp_set = np.zeros([num_samples, len(y_vals)])

    for sample_index, Te in enumerate(Te_samples):
        for radial_index, y in enumerate(y_vals):
            temp_set[sample_index, radial_index] = Te(0,y)

    mean_Te = np.zeros(len(y_vals))
    sigma_Te = np.zeros(len(y_vals))

    for r_index in range(len(y_vals)):
        mean_Te[r_index] = np.mean(temp_set[:, r_index])
        sigma_Te[r_index] = np.std(temp_set[:, r_index])

    # For now I will use this for the spatial coordinates
    x_avg = np.array([108.5, 116.5, 125.5, 133.5, 141.5, 149.5, 157.5, 165.5, 173.5, 182., 190.5, 198.5, 206.5, 214.5, 222.5, 230.5, 238.5,
                      247.5, 255.5, 263.5, 271.5, 279.5, 287.5, 295.5, 304., 312.5, 320.5, 328.5, 336.5, 344.5, 352.5, 360.5, 369.5])

    return {'Te0':Te0, 'alpha':alpha, 'posterior':p_of_k/norm,
            'k_hat':k_data, 'k_hat_sigma':k_data_err, 'x_avg':x_avg, 
            'marginal':{'Te0':{'dist':marginal_Teo, 'mean':Te0_mean, 'mode':Te0_mode},
                        'alpha':{'dist':marginal_alpha, 'mean':alpha_mean, 'mode':alpha_mode}},
            'samples':{'Te0':rand_Te0, 'alpha':rand_alpha, 'profiles':Te_samples},
            'result':{'mean':mean_Te, 'sigma':sigma_Te, 'radius':y_vals}
           }

def sample_2d(num_samples, p_of_k, Te0, alpha):
    """
    Used to sample properly correlated values from the discritized 2D distribution.
    """
    # Draw from the joint distribution by unwrapping it - have to renormalize it!
    p_of_k_1d = p_of_k.flatten()
    indices = np.arange(len(p_of_k_1d))
    norm_flat = np.trapz(p_of_k_1d, x=indices)
    p_of_k_1d /= norm_flat

    # Get the samples
    Te0_samples = np.zeros(num_samples)
    alpha_samples = np.zeros(num_samples)
    
    bins = np.zeros(len(p_of_k_1d)+1)
    bins[1:] = np.cumsum(p_of_k_1d)
    
    for sample_n, val in enumerate(np.random.rand(num_samples)):
        index = 0
        while not (val > bins[index] and val < bins[index+1]):
            index += 1
        
        # Transform back to the dersired coordinates
        temp_n, alpha_n = np.unravel_index(index, p_of_k.shape)
        Te0_samples[sample_n] = Te0[temp_n]
        alpha_samples[sample_n] = alpha[alpha_n]
        
    return Te0_samples, alpha_samples

# ------------------------------------------------------- Deprecated -------------------------------------------------------

def compute_k_hat_set(profiles, thresholds):
    """
    Computes the full set of k-hat for each cluster of 8 pixels, given the measurements and thresholds. This will work for both synthetic
    and real data. This version is modified from the previous version to fit only a single frame
    
    Inputs:
        - profiles = (dict) Contains entries profiles[Ec][x_index] = (array) where Ec is an element of thresholds. Theses are
                the measurements for each cluster of thresholds, so that profiles[4.0][0] and profiles[4.2][0] approximately
                share lines of sight, for example.
        - thresholds = (array of floats) These are the 8 energies at which the lower thresholds were set. They are the
                keys of the profiles dictionary.
    """
    # This routine assumes that all profiles have the same shape
    num_pixels = len(profiles[thresholds[0]])
    
    k_hat_set = np.zeros([num_pixels])
    k_hat_err = np.zeros([num_pixels])
    
    for index in range(num_pixels):
        y_data = np.array([profiles[Ec][index] for Ec in thresholds])

        try:
            params, pcov = np.polyfit(thresholds, np.log(y_data), 1, w=np.sqrt(y_data), cov=True)
            k_hat_set[index] = -1.0/params[0]
            k_hat_err[index] = np.sqrt(pcov[0,0])/(params[0]**2)
        except:
            k_hat_set[index] = np.nan
            k_hat_err[index] = np.nan
            
    return k_hat_set, k_hat_err


def get_k_model(Te0, alpha, ni_Al_profile, shot, Ew_fwhm=1300., delta_a=0.06, delta_h=0.01, ne=0.8, num_cores=16):
    """
    """
    # Load threshold data from the supplied shot
    MST_data = data.load_ME(shot, direction='horizontal')
    MST_data = data.load_ME_horiz(MST_data)
    Ec_map = MST_data['thresholds'][:,100]*1000.
    Ew_map = np.ones(487)*Ew_fwhm/(2*np.sqrt(2*np.log(2)))

    # Create the plasma profiles
    Te_profile = phys.Temperature_Alpha(Te0, alpha=alpha, beta=4.0, delta_a=delta_a, delta_h=delta_h)
    ne_profile = phys.Electron_Density_Alpha(ne, alpha=4.2, beta=4.0, delta_a=delta_a, delta_h=delta_h)
    MST_plasma = plasma.Plasma(Te_profile=Te_profile, ne_profile=ne_profile)
    MST_plasma.add_ions('Al', 13, ni_Al_profile, ignore_stages=range(1,7))
    
    # Take the data
    p3_det = det.Pilatus3_Detector(Ec_map, Ew_map)
    p3_det.look_at_plasma(MST_plasma)
    counts = p3_det.take_data(1.0, num_cores=num_cores)

    # Process the data
    measurements = [counts, counts]
    time_ms = np.array([1, 2])
    sim_dict = data.load_ME_sim(measurements, time_ms, MST_data['thresholds'])
    thresholds = MST_data['profiles']['thresholds']
    profiles_sim = {Ec:sim_dict['profiles']['counts'][Ec][:,0] for Ec in thresholds}
    k_sim, sigma_sim = compute_k_hat_set(profiles_sim, thresholds)
    
    return k_sim


def k_hat_scan(Te0_set, alpha_set, ni_Al_profile, shot, Ew_fwhm=1300., delta_a=0.06, delta_h=0.01, ne=0.8, resume=False, fname='k_scan_PPCD.pkl', num_cores=16):
    """
    """
    # Extract the impact parameters

    # Time the calculations
    start_time = time.time()

    if not resume:
        print('Starting new temperature scan.')
        results = {'Te0':Te0_set, 'alpha':alpha_set, 'k_hat':np.zeros([len(Te0_set), len(alpha_set), 60])}

        for temp_n, Te0 in enumerate(Te0_set):
            for al_n, alpha in enumerate(alpha_set):
                results['k_hat'][temp_n, al_n, :] = get_k_model(Te0, alpha, ni_Al_profile, shot, num_cores=num_cores,
                                                                Ew_fwhm=Ew_fwhm, delta_a=delta_a, delta_h=delta_h, ne=ne)

                print('Completed alpha = {0:.1f}.'.format(alpha))

            # Save progress in case of a crash
            print('Completed Te0 = {0:.1f}, {1:d}/{2:d} ({3:.1f}%).'.format(Te0, temp_n+1, len(Te0_set), 100.*float(temp_n)/len(Te0_set)))
            results['index'] = temp_n
            pickle.dump(results, open(fname, 'wb'))

    else:
        # Pick up where a previous scan left off
        print('Resuming temperature scan')
        results = pickle.load(open(fname, 'rb'))
        offset = results['index'] + 1

        for index, Te0 in enumerate(results['Te0'][offset:]):
            for al_n, alpha in enumerate(results['alpha']):
                temp_n = index + offset

                results['k_hat'][temp_n, al_n, :] = get_k_model(Te0, alpha, ni_Al_profile, shot,
                                                                Ew_fwhm=Ew_fwhm, delta_a=delta_a, delta_h=delta_h, ne=ne)

                print('Completed alpha = {0:.1f}.'.format(alpha))
                time.sleep(1)

            # Save progress in case of a crash
            print('Completed Te0 = {0:.1f}, {1:d}/{2:d} ({3:.1f}%).'.format(Te0, temp_n+1, len(results['Te0']), 100.*float(temp_n)/len(results['Te0'])))
            results['index'] = temp_n
            pickle.dump(results, open(fname, 'wb'))

    # Print timing data
    end_time = time.time()
    delta_t = end_time-start_time
    print('{0:.1f} min. elapsed.'.format(delta_t/60.))

    return results

def k_hat_model_PPCD(Te0, alpha, beta=4.0, shot=1180928081, Ew_fwhm=1300., num_cores=16, start_n=13, end_n=46, ignore=[22]):
    """
    This function takes in the Te profile parameters for a PPCD MST plasma and returns the model k_hat (continuum slope)
    measruements for each pixel. It also takes a shot number in order to load the appropriate thresholds. Assumes a neutral
    density profile at 17.5 ms.
    """
    # Load threshold data from the supplied shot
    MST_data = data.load_ME(shot, frames=[8], center_only=True, remove_edges=True)
    Ec_map = MST_data['thresholds'][:,100]*1000.
    Ew_map = np.ones(487)*Ew_fwhm/(2*np.sqrt(2*np.log(2)))

    # Create the plasma profiles from standard PPCD parameters
    delta_a = 0.06
    delta_h = 0.01
    ne = 0.6

    Te_profile = phys.Temperature_Alpha(Te0, alpha=alpha, beta=beta, delta_a=delta_a, delta_h=delta_h)
    ne_profile = phys.Electron_Density_Alpha(ne, alpha=4.2, beta=4.0, delta_a=delta_a, delta_h=delta_h)
    ni_Al_profile = phys.Ion_Density_Alpha(3.0E-3, alpha=15, beta=2, element='Al', delta_a=delta_a, delta_h=delta_h)
    nH_profile = phys.Neutral_Density_Profile(17.5)

    MST_plasma = plasma.Plasma(Te_profile=Te_profile, ne_profile=ne_profile, nH_profile=nH_profile)
    MST_plasma.add_ions('Al', 13, ni_Al_profile, ignore_stages=range(1,7))
    
    # Take the data
    p3_det = det.Pilatus3_Detector(Ec_map, Ew_map, num_cores=num_cores)
    p3_det.look_at_plasma(MST_plasma)
    counts = p3_det.take_data(1.0)

    # Process the data
    measurements = [counts]
    time_ms = np.array([1])

    k_hat = data.load_8_color_sim(measurements, time_ms, MST_data['thresholds'], remove_edges=True, data=False,
                             start_n=start_n, end_n=end_n, ignore=ignore)

    return k_hat['k_hat'][0]